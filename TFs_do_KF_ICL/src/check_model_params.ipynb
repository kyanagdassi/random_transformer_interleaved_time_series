{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ce32fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sultand/TFs_do_KF_ICL/src\n",
      "Using device: cuda\n",
      "/home/sultand/TFs_do_KF_ICL/src\n",
      "Using device: cuda\n",
      "CUDA_VISIBLE_DEVICES: None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Liberation Serif'\n",
    "\n",
    "import logging\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import os\n",
    "from data_processing import gen_ckpt_steps\n",
    "from conv_plots_funcs import get_seg_starts_per_config\n",
    "import torch\n",
    "import gc\n",
    "from core.config import Config\n",
    "from data_train import set_config_params, gen_ckpt_pred_steps\n",
    "from get_last_checkpoint import split_path\n",
    "from haystack_plots import load_quartiles_ckpt_files\n",
    "from models import GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cda1701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ORTHO HAAR TINY MODEL\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = Config()\n",
    "model_name = \"ortho_haar_tiny\" #\"ortho_haar_medium_single_gpu\"\n",
    "\n",
    "output_dir, ckpt_dir, experiment_name = set_config_params(config, model_name)\n",
    "\n",
    "datasource = \"val\"\n",
    "\n",
    "\n",
    "colors = ['#000000', '#005CAB', '#E31B23', '#FFC325', '#00A651', '#9B59B6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7e1c4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT2(\n",
      "  (_read_in): Linear(in_features=57, out_features=72, bias=True)\n",
      "  (_backbone): GPT2Model(\n",
      "    (wte): Embedding(50257, 72)\n",
      "    (wpe): Embedding(2048, 72)\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-2): 3 x GPT2Block(\n",
      "        (ln_1): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D(nf=216, nx=72)\n",
      "          (c_proj): Conv1D(nf=72, nx=72)\n",
      "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D(nf=288, nx=72)\n",
      "          (c_proj): Conv1D(nf=72, nx=288)\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((72,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (_read_out): Linear(in_features=72, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # check if cuda is available\n",
    "\n",
    "ckpt = 1000\n",
    "filename = f\"step={ckpt}.ckpt\"\n",
    "ckpt_path = ckpt_dir + \"/checkpoints/\" + filename\n",
    "\n",
    "config.override(\"ckpt_path\", ckpt_path)\n",
    "#load model from ckpt_dir``\n",
    "model = GPT2.load_from_checkpoint(config.ckpt_path,\n",
    "                                n_dims_in=config.n_dims_in, n_positions=config.n_positions,\n",
    "                                n_dims_out=config.n_dims_out, n_embd=config.n_embd,\n",
    "                                n_layer=config.n_layer, n_head=config.n_head, use_pos_emb=config.use_pos_emb, map_location=device, strict=True).eval().to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a739408c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters (excluding wte and wpe): 194,117\n"
     ]
    }
   ],
   "source": [
    "total_params = 0\n",
    "for name, param in model.named_parameters():\n",
    "    if not (\"wte\" in name or \"wpe\" in name):\n",
    "        # print(f\"{name}: {param.shape}, {param.numel()}\")\n",
    "        total_params += param.numel()\n",
    "print(f\"Total parameters (excluding wte and wpe): {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d482731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_count(model, context_len):\n",
    "    total_params = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if not (\"wte\" in name or \"wpe\" in name):\n",
    "            total_params += param.numel()\n",
    "\n",
    "        #get the shape of wpe\n",
    "        elif \"wpe\" in name:\n",
    "            wpe_shape = param.shape\n",
    "            print(f\"{name}: {param.shape}, {param.numel()}\")\n",
    "            wpe_params = context_len * wpe_shape[1]\n",
    "            total_params += wpe_params\n",
    "            print(f\"wpe params: {wpe_params:,}\")\n",
    "\n",
    "    print(f\"Total parameters (excluding wte and wpe): {total_params:,}\")\n",
    "    return total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "772256a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_backbone.wpe.weight: torch.Size([2048, 72]), 147456\n",
      "wpe params: 18,072\n",
      "Total parameters (excluding wte and wpe): 212,189\n"
     ]
    }
   ],
   "source": [
    "param_count = parameter_count(model, config.n_positions+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9507011",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
